{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba3da954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning LHS sampling\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c18b9e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of variables = 22870512900\n"
     ]
    }
   ],
   "source": [
    "# Next section is examples of creating LHS from list of variables. Take, for instance, an eight-layer RTS laminate.\n",
    "# [pm phi_1 < T0_1 | T1_1 > n_1 , pm phi_2 < T0_2 | T1_2 > n_2]s such that there are 8 variables\n",
    "\n",
    "# x = [phi1, t01, t11, n1, phi2, t02, t12, n2]\n",
    "\n",
    "# as n_i is dependent on phi_i, normalise n_i to be between 0 and 1 and then, dependent on phi, define integer value\n",
    "\n",
    "# total number of samples for an eight-layer RTS laminate (assuming symmetry and balance):\n",
    "# n_phi=0 = [0, 1, ..., 10] therefore when phi = 0, number of variables for n = 11\n",
    "# n_phi=90 [0, 1, ..., 18] therefore when phi = 90, number of variables for n = 18\n",
    "# t0 = t1 = [0, 1, ..., 70] therefore number of variables = 71\n",
    "# each cylinder (of eight layers) is defined by two RTS lamina: x = [phi1, t01, t11, n1, phi2, t02, t12, n2]\n",
    "\n",
    "# total number of samples (phi = 0) + (phi = 0 and 90) + (phi = 90)\n",
    "n_tot = (71**4*11**2) + 2*(71**4*11*19) + (71**4*19**2)\n",
    "print(f'Total number of variables = {n_tot}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdf504d",
   "metadata": {},
   "source": [
    "# Create LHS samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d61367a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rts_lhs():\n",
    "\n",
    "    # defining function to take LHS (n_samples-by-n_variables matrix of value 0 -> 1) into useable designs\n",
    "    def lhs_to_lamina(lhs_in, cyl, lam_type):\n",
    "\n",
    "        import numpy as np\n",
    "\n",
    "        # lhs_in = unity-normalised LHS\n",
    "        # cyl = [radius, length, thickness]\n",
    "        # lam_type = 1 (RTS) or lam_type = 0 (SF)\n",
    "\n",
    "        # return = lamina = [[phi1, t01, t11, n1, phi2, t02, t12, n2]*n_var]\n",
    "\n",
    "        # define sub-function that takes phi and returns n_max based on geometry\n",
    "        def phi_to_n_max(cyl, phi):\n",
    "\n",
    "            # cyl = [radius, length, thickness]\n",
    "            # phi = 0 (axial) or = 90 (circumferential)\n",
    "\n",
    "            # assume MSR (minimum steering radius) is 50, therefore 1 period is 100 mm (minimum)\n",
    "            msr = 100\n",
    "\n",
    "            if phi == 0:\n",
    "                n_max = np.floor(cyl[1]//msr) + 1\n",
    "            elif phi == 90:\n",
    "                n_max = np.floor(2*np.pi*cyl[0]//msr) + 1\n",
    "            else:\n",
    "                SyntaxError('Phi is not defined as 0 or 90 degree')\n",
    "\n",
    "            return n_max\n",
    "\n",
    "        lamina = np.zeros((np.shape(lhs_in)))\n",
    "\n",
    "        # if lam_type = 1 (i.e. RTS laminate)\n",
    "        if lam_type:\n",
    "\n",
    "            for i, l in enumerate(lhs_in):\n",
    "                lamina[i, 0] = round(l[0])*90 # defining phi_1\n",
    "                lamina[i, 1] = round(l[1]*70) # defining t0_1\n",
    "                lamina[i, 2] = round(l[2]*70) # defining t1_1\n",
    "                lamina[i, 3] = int(l[3]*phi_to_n_max(cyl, lamina[i,0])) # defining n_1\n",
    "                lamina[i, 4] = round(l[4])*90 # defining phi_2\n",
    "                lamina[i, 5] = round(l[5]*70) # defining t0_2\n",
    "                lamina[i, 6] = round(l[6]*70) # defining t1_2\n",
    "                lamina[i, 7] = int(l[7]*phi_to_n_max(cyl, lamina[i,4])) # defining n_2\n",
    "\n",
    "        # if lam_type = 0 (i.e. SF laminate)\n",
    "        elif not lam_type:\n",
    "\n",
    "            for i, l in enumerate(lhs_in):\n",
    "                lamina[i, 0] = round(l[0]*90) # defining alpha_1\n",
    "                lamina[i, 1] = round(l[1]*90) # defining alpha_2\n",
    "\n",
    "        return np.asarray(lamina)\n",
    "\n",
    "    ## Rapid tow sheared (RTS) laminates\n",
    "    # number of RTS variables: [pm phi_1 < T0_1 | T1_1 > n_1 , pm phi_2 < T0_2 | T1_2 > n_2]s\n",
    "    n_rts_var = 8\n",
    "\n",
    "    # defining number of samples for RTS laminates\n",
    "    n_rts_sam = 10*n_rts_var\n",
    "    # the number of samples is based on the 'levels' of each variable:\n",
    "    # # https://stats.stackexchange.com/questions/58201/how-to-determine-the-sample-size-of-a-latin-hypercube-sampling\n",
    "    # SMT use 10 * n dimensions. We have 8 dimensions, therefore 80 samples. Could change... Probably need to infill after initial \n",
    "\n",
    "    from pyDOE2 import lhs\n",
    "\n",
    "    # call LHS from pyDOE2 for RTS laminates\n",
    "    lhs_rts  = lhs(n_rts_var, n_rts_sam)\n",
    "\n",
    "    # cyl is a vector with [radius, length, thickness] in mm of the cylinder in question\n",
    "    # cyl is needed to define max periodicty if RTS laminate is chosen\n",
    "    cyl = [300, 1040, 1.05]\n",
    "\n",
    "    # transform unity lhs to laminate definition for RTS (lam_type = 1)\n",
    "    rts_lams = lhs_to_lamina(lhs_rts, cyl, 1)\n",
    "\n",
    "    return rts_lams\n",
    "\n",
    "rts_lams = rts_lhs()\n",
    "\n",
    "# # transform unity lhs to laminate definition for SF (lam_type = 0)\n",
    "# sf_lams = lhs_to_lamina(lhs_sf, cyl, 0)\n",
    "\n",
    "# print(rts_lams[0:4])\n",
    "\n",
    "# print(sf_lams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acac9c79",
   "metadata": {},
   "source": [
    "# Run LHS samples through \"Abaqus\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a67e116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[153.71581307  48.55744832 141.35068934 171.98547676]\n"
     ]
    }
   ],
   "source": [
    "# Run LHS with Abaqus. For now, use dummy function where y (output) is the sum of the variables\n",
    "def dummy_func(x_in):\n",
    "    \n",
    "    y_out = []\n",
    "    \n",
    "    for x in x_in:\n",
    "        y_out.append(sum(x) + sum(x)/np.sqrt(sum(x)) + np.sin(x[1]))\n",
    "    \n",
    "    return np.asarray(y_out)\n",
    "\n",
    "y_rts = dummy_func(rts_lams)\n",
    "print(y_rts[0:4])\n",
    "# y_sf = dummy_func(sf_lams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e54061",
   "metadata": {},
   "source": [
    "# Calculate convergence crit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "633e215c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________________________________________\n",
      "   \n",
      "                                  Kriging\n",
      "___________________________________________________________________________\n",
      "   \n",
      " Problem size\n",
      "   \n",
      "      # training points.        : 64\n",
      "   \n",
      "___________________________________________________________________________\n",
      "   \n",
      " Training\n",
      "   \n",
      "   Training ...\n",
      "   Training - done. Time (sec):  0.2993660\n",
      "___________________________________________________________________________\n",
      "   \n",
      " Evaluation\n",
      "   \n",
      "      # eval points. : 16\n",
      "   \n",
      "   Predicting ...\n",
      "   Predicting - done. Time (sec):  0.0010026\n",
      "   \n",
      "   Prediction time/pt. (sec) :  0.0000627\n",
      "   \n",
      "[[142.64540374]\n",
      " [192.14491005]\n",
      " [415.61008792]\n",
      " [288.6308756 ]\n",
      " [196.44573248]\n",
      " [140.19795701]\n",
      " [224.73962105]\n",
      " [167.06057359]\n",
      " [338.40215654]\n",
      " [336.143444  ]\n",
      " [184.08918978]\n",
      " [155.53355461]\n",
      " [311.2823489 ]\n",
      " [330.42802524]\n",
      " [259.17168   ]\n",
      " [298.98867917]]\n",
      "[141.35068934 192.18313505 414.35305591 285.57615675 197.44069451\n",
      " 139.95377905 226.48221497 168.40627553 332.77639863 332.78460998\n",
      " 186.54887159 158.02822217 312.13578645 332.37033299 259.66069699\n",
      " 294.56334302]\n"
     ]
    }
   ],
   "source": [
    "from smt.surrogate_models import KRG\n",
    "\n",
    "def split_data(data_in, data_out, train_per, test_per):\n",
    "    \n",
    "    import numpy as np\n",
    "    from random import sample\n",
    "    from random import seed\n",
    "    \n",
    "    # set seed \n",
    "    seed(1)\n",
    "    \n",
    "    # define number of data entries\n",
    "    data_nums = np.arange(0, len(data_in)).tolist()\n",
    "    \n",
    "    # get data indicies that will be trained on (train_per %) by randomly sampling (with set seed)\n",
    "    train_nums = np.sort(sample(data_nums, round(len(data_in)*train_per/100)))\n",
    "    \n",
    "    # keep back data indicies that will be tested on (test_per %)\n",
    "    test_nums = np.asarray([x for x in data_nums if x not in train_nums])\n",
    "    \n",
    "    # putting training data together\n",
    "    train_in = data_in[train_nums[:]]\n",
    "    train_out = np.atleast_2d(data_out[train_nums[:]]).T\n",
    "    train_data = np.concatenate((train_in,train_out),axis=1)\n",
    "    \n",
    "    # putting testing data together\n",
    "    test_in = data_in[test_nums[:]]\n",
    "    test_out = np.atleast_2d(data_out[test_nums[:]]).T\n",
    "    test_data = np.concatenate((test_in, test_out),axis=1)\n",
    "\n",
    "    # check data_in = train_in + test_in and data_out = train_out + test_out\n",
    "    if len(data_in) != len(train_in) + len(test_in):\n",
    "        SyntaxError('Length of train_in + test_in is not the same as data_in: data has been missed/added?!')\n",
    "    if len(data_out) != len(train_out) + len(test_out):\n",
    "        SyntaxError('Length of train_out + test_out is not the same as data_out: data has been missed/added?!')\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "rts_train, rts_test = split_data(rts_lams, y_rts, 80, 20)\n",
    "# sf_train, sf_test = split_data(sf_lams, y_sf, 80, 20)\n",
    "\n",
    "# RTS laminates\n",
    "sm_rts = KRG(theta0=[1e-1])\n",
    "sm_rts.set_training_values(rts_train[:,0:8], rts_train[:,8])\n",
    "sm_rts.train()\n",
    "\n",
    "rts_pred = sm_rts.predict_values(rts_test[:,0:8])\n",
    "print(rts_pred)\n",
    "print(rts_test[:,8])\n",
    "\n",
    "# estimated variance\n",
    "# s2 = sm.predict_variances(x)\n",
    "# derivative according to the first variable\n",
    "# dydx = sm.predict_derivatives(xt, 0)\n",
    "# fig, axs = plt.subplots(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec566d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
