{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba3da954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning LHS sampling\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c18b9e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of variables = 22870512900\n"
     ]
    }
   ],
   "source": [
    "# Next section is examples of creating LHS from list of variables. Take, for instance, an eight-layer RTS laminate.\n",
    "# [pm phi_1 < T0_1 | T1_1 > n_1 , pm phi_2 < T0_2 | T1_2 > n_2]s such that there are 8 variables\n",
    "\n",
    "# x = [phi1, t01, t11, n1, phi2, t02, t12, n2]\n",
    "\n",
    "# as n_i is dependent on phi_i, normalise n_i to be between 0 and 1 and then, dependent on phi, define integer value\n",
    "\n",
    "# total number of samples for an eight-layer RTS laminate (assuming symmetry and balance):\n",
    "# n_phi=0 = [0, 1, ..., 10] therefore when phi = 0, number of variables for n = 11\n",
    "# n_phi=90 [0, 1, ..., 18] therefore when phi = 90, number of variables for n = 18\n",
    "# t0 = t1 = [0, 1, ..., 70] therefore number of variables = 71\n",
    "# each cylinder (of eight layers) is defined by two RTS lamina: x = [phi1, t01, t11, n1, phi2, t02, t12, n2]\n",
    "\n",
    "# total number of samples (phi = 0) + (phi = 0 and 90) + (phi = 90)\n",
    "n_tot = (71**4*11**2) + 2*(71**4*11*19) + (71**4*19**2)\n",
    "print(f'Total number of variables = {n_tot}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdf504d",
   "metadata": {},
   "source": [
    "# Create LHS samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d61367a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. 10. 17.  3. 90. 20. 44.  0.]\n",
      " [90. 33. 15. 17.  0. 37. 26.  1.]\n",
      " [ 0. 21.  6.  5.  0.  7. 30.  8.]\n",
      " [90. 12. 31. 12.  0. 24. 16.  2.]\n",
      " [90.  2. 22.  0.  0. 23. 43.  0.]\n",
      " [ 0. 66. 49.  8.  0. 22. 57.  7.]\n",
      " [ 0. 35. 53.  5. 90. 50. 52. 16.]\n",
      " [90. 40. 16.  5. 90. 43.  4. 18.]\n",
      " [ 0. 58. 40.  1. 90. 18.  6.  6.]\n",
      " [ 0. 67. 23.  3.  0. 58. 12.  6.]\n",
      " [ 0. 46. 33.  5.  0. 29. 25.  1.]\n",
      " [ 0.  6. 70.  7.  0. 28.  4.  7.]\n",
      " [ 0. 17. 28. 10.  0. 65. 26. 10.]\n",
      " [90. 60.  5.  5. 90. 67. 50. 15.]\n",
      " [90. 16. 66. 16.  0. 30. 11.  8.]\n",
      " [90. 56. 27. 17. 90. 53.  7. 14.]\n",
      " [90. 68. 32.  1. 90. 40. 54.  3.]\n",
      " [90. 41. 38.  9. 90. 15. 12. 17.]\n",
      " [ 0. 56. 47.  1.  0. 38. 14.  7.]\n",
      " [90. 52. 22.  1. 90. 11. 29. 11.]\n",
      " [90. 38. 60.  1. 90. 68. 69. 13.]\n",
      " [ 0. 45. 20.  1. 90. 33.  3.  1.]\n",
      " [ 0. 69.  9.  1.  0. 50. 14.  6.]\n",
      " [ 0. 25. 68.  8.  0. 34. 21.  3.]\n",
      " [ 0. 42. 59.  6. 90.  1.  0. 12.]\n",
      " [90. 30. 64. 10. 90. 70. 22. 13.]\n",
      " [90. 45. 44. 12.  0.  6. 35.  3.]\n",
      " [90. 64. 49.  8.  0. 26. 58.  9.]\n",
      " [90. 52.  8. 14.  0. 59.  2.  9.]\n",
      " [ 0. 59. 34.  6. 90.  8. 65. 10.]\n",
      " [ 0. 11. 20. 10. 90. 54. 24.  4.]\n",
      " [ 0. 26. 65.  1.  0. 64. 63.  3.]\n",
      " [90. 18. 11. 13. 90. 35. 59.  3.]\n",
      " [ 0. 42. 13.  9. 90. 64. 47.  9.]\n",
      " [ 0. 61.  3.  2. 90. 39. 60.  6.]\n",
      " [ 0. 58. 43.  0.  0. 31. 33.  5.]\n",
      " [90. 34. 25. 18. 90. 57. 34.  5.]\n",
      " [90.  9. 55.  1.  0. 22. 58. 10.]\n",
      " [90. 46. 19.  4.  0. 44. 61.  1.]\n",
      " [ 0. 16. 42.  2.  0. 56. 32.  1.]\n",
      " [90. 50.  6. 16. 90.  0. 39. 12.]\n",
      " [ 0. 37.  1.  3. 90. 34. 22.  7.]\n",
      " [ 0. 53. 34.  9. 90. 36. 66. 16.]\n",
      " [90.  4. 65.  7. 90. 62. 51. 12.]\n",
      " [ 0. 68. 35. 10.  0. 13. 49.  1.]\n",
      " [ 0. 23. 31. 10.  0. 10. 46.  8.]\n",
      " [ 0. 55. 14.  6. 90. 49. 38. 16.]\n",
      " [ 0.  1. 50.  7.  0. 47.  3.  4.]\n",
      " [90. 54. 45. 11. 90. 25. 18.  1.]\n",
      " [90. 36. 29. 11.  0. 41. 10.  6.]\n",
      " [ 0. 30. 57.  0. 90. 60. 31.  1.]\n",
      " [ 0. 48. 68.  7. 90. 12. 62.  8.]\n",
      " [90. 20.  2. 17.  0. 61. 54.  5.]\n",
      " [90.  3. 61. 12.  0. 54. 42.  6.]\n",
      " [90. 65. 58.  7. 90. 16. 28.  9.]\n",
      " [90. 49. 14.  0.  0. 17. 29.  8.]\n",
      " [90. 31. 54.  9. 90. 51.  8. 16.]\n",
      " [90. 13. 54.  3.  0.  3. 38.  6.]\n",
      " [ 0.  4. 52.  8.  0.  9. 43.  8.]\n",
      " [90. 43. 52.  7. 90. 42.  8.  3.]\n",
      " [ 0. 27.  4.  1. 90. 69. 69.  4.]\n",
      " [ 0. 39. 39.  3.  0. 12. 20. 10.]\n",
      " [90. 36. 12.  6.  0.  3. 53.  4.]\n",
      " [ 0. 50. 27.  5.  0. 19. 39.  0.]\n",
      " [ 0. 23. 37.  9.  0. 45. 48.  3.]\n",
      " [ 0. 12. 25.  9. 90. 26. 68. 18.]\n",
      " [ 0.  7. 24.  4. 90. 30. 65.  7.]\n",
      " [ 0. 32. 46.  2.  0. 57. 10.  1.]\n",
      " [90. 19. 67. 14. 90. 48. 34.  5.]\n",
      " [ 0. 29. 43.  4. 90. 32. 24.  8.]\n",
      " [90.  8.  7.  3. 90.  4. 55.  0.]\n",
      " [90. 63. 18.  4. 90. 62. 18.  1.]\n",
      " [90. 24.  0. 11. 90. 40. 62.  9.]\n",
      " [90. 19. 62. 14.  0. 20. 36.  5.]\n",
      " [90.  0. 47. 13.  0. 66. 49.  8.]\n",
      " [90.  6. 37.  6.  0. 46. 17. 10.]\n",
      " [90. 27. 58. 10.  0.  5. 41.  6.]\n",
      " [ 0. 61. 41.  5. 90. 15. 45. 16.]\n",
      " [ 0. 63. 62.  4. 90.  5. 16.  4.]\n",
      " [90. 14. 10. 15.  0. 52. 67.  4.]]\n",
      "[[74. 82.]\n",
      " [16. 51.]\n",
      " [78. 70.]\n",
      " [11. 20.]\n",
      " [28. 31.]\n",
      " [41. 56.]\n",
      " [ 1. 61.]\n",
      " [87. 34.]\n",
      " [85. 64.]\n",
      " [59. 38.]\n",
      " [38.  1.]\n",
      " [72. 14.]\n",
      " [64. 25.]\n",
      " [51. 48.]\n",
      " [54. 13.]\n",
      " [34. 79.]\n",
      " [22.  8.]\n",
      " [24. 74.]\n",
      " [ 7. 41.]\n",
      " [47. 86.]]\n"
     ]
    }
   ],
   "source": [
    "# defining function to take LHS (n_samples-by-n_variables matrix of value 0 -> 1) into useable designs\n",
    "def lhs_to_lamina(lhs_in, cyl, lam_type):\n",
    "\n",
    "    # lhs_in = unity-normalised LHS\n",
    "    # cyl = [radius, length, thickness]\n",
    "    # lam_type = 1 (RTS) or lam_type = 0 (SF)\n",
    "    \n",
    "    # return = lamina = [[phi1, t01, t11, n1, phi2, t02, t12, n2]*n_var]\n",
    "\n",
    "    # define sub-function that takes phi and returns n_max based on geometry\n",
    "    def phi_to_n_max(cyl, phi):\n",
    "        \n",
    "        # cyl = [radius, length, thickness]\n",
    "        # phi = 0 (axial) or = 90 (circumferential)\n",
    "        \n",
    "        # assume MSR (minimum steering radius) is 50, therefore 1 period is 100 mm (minimum)\n",
    "        msr = 100\n",
    "        \n",
    "        if phi == 0:\n",
    "            n_max = np.floor(cyl[1]//msr) + 1\n",
    "        elif phi == 90:\n",
    "            n_max = np.floor(2*np.pi*cyl[0]//msr) + 1\n",
    "        else:\n",
    "            SyntaxError('Phi is not defined as 0 or 90 degree')\n",
    "            \n",
    "        return n_max\n",
    "    \n",
    "    lamina = np.zeros((np.shape(lhs_in)))\n",
    "    \n",
    "    # if lam_type = 1 (i.e. RTS laminate)\n",
    "    if lam_type:\n",
    "    \n",
    "        for i, l in enumerate(lhs_in):\n",
    "            lamina[i, 0] = round(l[0])*90 # defining phi_1\n",
    "            lamina[i, 1] = round(l[1]*70) # defining t0_1\n",
    "            lamina[i, 2] = round(l[2]*70) # defining t1_1\n",
    "            lamina[i, 3] = int(l[3]*phi_to_n_max(cyl, lamina[i,0])) # defining n_1\n",
    "            lamina[i, 4] = round(l[4])*90 # defining phi_2\n",
    "            lamina[i, 5] = round(l[5]*70) # defining t0_2\n",
    "            lamina[i, 6] = round(l[6]*70) # defining t1_2\n",
    "            lamina[i, 7] = int(l[7]*phi_to_n_max(cyl, lamina[i,4])) # defining n_2\n",
    "    \n",
    "    # if lam_type = 0 (i.e. SF laminate)\n",
    "    elif not lam_type:\n",
    "        \n",
    "        for i, l in enumerate(lhs_in):\n",
    "            lamina[i, 0] = round(l[0]*90) # defining alpha_1\n",
    "            lamina[i, 1] = round(l[1]*90) # defining alpha_2\n",
    "    \n",
    "    return lamina\n",
    "\n",
    "## Rapid tow sheared (RTS) laminates\n",
    "# number of RTS variables: [pm phi_1 < T0_1 | T1_1 > n_1 , pm phi_2 < T0_2 | T1_2 > n_2]s\n",
    "n_rts_var = 8\n",
    "\n",
    "# defining number of samples for RTS laminates\n",
    "n_rts_sam = 10*n_rts_var\n",
    "# the number of samples is based on the 'levels' of each variable:\n",
    "# # https://stats.stackexchange.com/questions/58201/how-to-determine-the-sample-size-of-a-latin-hypercube-sampling\n",
    "# SMT use 10 * n dimensions. We have 8 dimensions, therefore 80 samples. Could change... Probably need to infill after initial \n",
    "\n",
    "from pyDOE2 import lhs\n",
    "\n",
    "# call LHS from pyDOE2 for RTS laminates\n",
    "lhs_rts  = lhs(n_rts_var, n_rts_sam)\n",
    "\n",
    "## Straight fibre (SF) laminates\n",
    "# number of SF variables: [pm alpha_1, pm alpha_2]s\n",
    "n_sf_var = 2\n",
    "\n",
    "# number of samples for SF laminates\n",
    "n_sf_sam = 10*n_sf_var\n",
    "\n",
    "# call LHS from pyDOE2 for SF laminates\n",
    "lhs_sf = lhs(n_sf_var, n_sf_sam)\n",
    "\n",
    "# cyl is a vector with [radius, length, thickness] in mm of the cylinder in question\n",
    "# cyl is needed to define max periodicty if RTS laminate is chosen\n",
    "cyl = [300, 1040, 1.05]\n",
    "\n",
    "# transform unity lhs to laminate definition for RTS (lam_type = 1)\n",
    "rts_lams = lhs_to_lamina(lhs_rts, cyl, 1)\n",
    "\n",
    "# transform unity lhs to laminate definition for SF (lam_type = 0)\n",
    "sf_lams = lhs_to_lamina(lhs_sf, cyl, 0)\n",
    "\n",
    "print(rts_lams)\n",
    "\n",
    "print(sf_lams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acac9c79",
   "metadata": {},
   "source": [
    "# Run LHS samples through Abaqus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a67e116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[319. 289. 200. 374. 160. 210. 366. 255. 191. 302. 298. 182. 359. 279.\n",
      " 198. 269. 273. 207. 185. 191. 301. 361. 178. 259. 328. 332. 177. 384.\n",
      " 220. 241. 266. 309. 230. 211. 117. 137. 272. 307. 304. 282. 403. 283.\n",
      " 316. 195. 164. 167. 264. 272. 195. 170. 190. 162. 267. 111. 241. 238.\n",
      " 241. 296. 277. 268. 101. 239. 193. 267. 195. 310. 105. 198. 242. 119.\n",
      " 255. 223. 334. 210. 216. 239. 299. 247. 327. 181.]\n"
     ]
    }
   ],
   "source": [
    "# Run LHS with Abaqus. For now, use dummy function where y (output) is the sum of the variables\n",
    "def dummy_func(x_in):\n",
    "    \n",
    "    y_out = []\n",
    "    \n",
    "    for x in x_in:\n",
    "        y_out.append(sum(x))\n",
    "    \n",
    "    return np.asarray(y_out)\n",
    "\n",
    "y = dummy_func(rts_lams)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e54061",
   "metadata": {},
   "source": [
    "# Calculate convergence crit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "633e215c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________________________________________\n",
      "   \n",
      "                                  Kriging\n",
      "___________________________________________________________________________\n",
      "   \n",
      " Problem size\n",
      "   \n",
      "      # training points.        : 80\n",
      "   \n",
      "___________________________________________________________________________\n",
      "   \n",
      " Training\n",
      "   \n",
      "   Training ...\n",
      "   Training - done. Time (sec):  0.3723986\n",
      "[[90.  9. 18.  3.  0. 17. 11.  3.]\n",
      " [ 0. 65. 41.  0.  0. 40. 11.  0.]\n",
      " [ 0. 14. 32.  2.  0. 61. 16.  1.]\n",
      " [ 0. 25. 34.  7. 90. 25. 31. 10.]\n",
      " [ 0. 53. 44.  9.  0. 43. 37.  6.]]\n",
      "___________________________________________________________________________\n",
      "   \n",
      " Evaluation\n",
      "   \n",
      "      # eval points. : 5\n",
      "   \n",
      "   Predicting ...\n",
      "   Predicting - done. Time (sec):  0.0000000\n",
      "   \n",
      "   Prediction time/pt. (sec) :  0.0000000\n",
      "   \n",
      "[[151.00013421]\n",
      " [157.00020191]\n",
      " [126.00004046]\n",
      " [222.00011038]\n",
      " [192.00007484]]\n",
      "[151. 157. 126. 222. 192.]\n"
     ]
    }
   ],
   "source": [
    "from smt.surrogate_models import KRG\n",
    "\n",
    "sm = KRG(theta0=[1e-1])\n",
    "sm.set_training_values(rts_lams, y)\n",
    "sm.train()\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "n_test = 5\n",
    "x_test = lhs_to_lamina(rng.random((n_test,8)),cyl,1)\n",
    "\n",
    "print(x_test)\n",
    "\n",
    "y_pred = sm.predict_values(x_test)\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "y_true = dummy_func(x_test)\n",
    "\n",
    "print(y_true)\n",
    "\n",
    "# estimated variance\n",
    "# s2 = sm.predict_variances(x)\n",
    "# derivative according to the first variable\n",
    "# dydx = sm.predict_derivatives(xt, 0)\n",
    "# fig, axs = plt.subplots(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
